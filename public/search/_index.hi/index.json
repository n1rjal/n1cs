[{"categories":[],"content":"Django has always been a quick go to framework that I mostly use when I need some result quickly. Start with the server or when I want to set up a quick server. DRF is used to create rest framework on top of Django. It has various components like viewsets, routers, serializes, etc. This article is going to be about serializer only.\nThe need of serializer Serializing and deserializing is the process of converting a value from one representation to another. It acts as a translator that translates one form of data to another and vice versa.\nSerializer vs Model Serializer Serializer in DRF is the class that is responsible for changing one form of object to another. Mostly python object to JSON and vice versa. It has various fields shown below\nI highly suggest you look into the documentation.\ndjango-rest-framework/rest_framework/fields.py at master · encode/django-rest-framework _Web APIs for Django. 🎸. Contribute to encode/django-rest-framework development by creating an account on GitHub._github.com Model Serializer is an abstract form of Serializer. It makes it easy to make a serializer for a Django model. If we look into the source code. There you will see a mapping from Django models fields to DRF serializer fields.\nclass ModelSerializer(Serializer): \u0026#34;\u0026#34;\u0026#34; A `ModelSerializer` is just a regular `Serializer`, except that: * A set of default fields are automatically populated. * A set of default validators are automatically populated. * Default `.create()` and `.update()` implementations are provided. The process of automatically determining a set of serializer fields based on the model fields is reasonably complex, but you almost certainly don\u0026#39;t need to dig into the implementation. If the `ModelSerializer` class doesn\u0026#39;t generate the set of fields that you need you should either declare the extragdiffering fields explicitly on the serializer class, or simply use a `Serializer` class. \u0026#34;\u0026#34;\u0026#34; serializer_field_mapping = { models.AutoField: IntegerField, models.BigIntegerField: IntegerField, models.BooleanField: BooleanField, models.CharField: CharField, models.CommaSeparatedIntegerField: CharField, models.DateField: DateField, models.DateTimeField: DateTimeField, models.DecimalField: DecimalField, models.DurationField: DurationField, models.EmailField: EmailField, models.Field: ModelField, models.FileField: FileField, models.FloatField: FloatField, models.ImageField: ImageField, models.IntegerField: IntegerField, models.NullBooleanField: BooleanField, models.PositiveIntegerField: IntegerField, models.PositiveSmallIntegerField: IntegerField, models.SlugField: SlugField, models.SmallIntegerField: IntegerField, models.TextField: CharField, models.TimeField: TimeField, models.URLField: URLField, models.UUIDField: UUIDField, models.GenericIPAddressField: IPAddressField, models.FilePathField: FilePathField, } if hasattr(models, \u0026#39;JSONField\u0026#39;): serializer_field_mapping[models.JSONField] = JSONField if postgres_fields: serializer_field_mapping[postgres_fields.HStoreField] = HStoreField serializer_field_mapping[postgres_fields.ArrayField] = ListField serializer_field_mapping[postgres_fields.JSONField] = JSONField serializer_related_field = PrimaryKeyRelatedField serializer_related_to_field = SlugRelatedField serializer_url_field = HyperlinkedIdentityField serializer_choice_field = ChoiceField # continue reading the source at https://github.com/encode/django-rest-framework/blob/master/rest _framework/serializers.py#L889\nSerializer Methods: In particular, if a `data=` argument is passed, then:\nis_valid() — Available. initial_data — Available. validated_data — Only available after calling `is_valid()` errors — Only available after calling `is_valid()` data — Only available after calling `is_valid()` If a `data=` argument is not passed, then:\nis_valid() — Not available. initial_data — Not available. validated_data — Not available. errors — Not available. data — Available. There are few other methods that can be used with a serializer, but you must define it yourself (for Serializer class) but it is not required for Model serializers meaning that you can save time using Model Serializer\ncreate(): A serializer method used to create data using the serializer’s validated data. Not implemented by default update(): Update the instance passed to the serializer using the new validated data delete(): Delete the instance passed to the serializer validate_(): Used to validate single value for a particular field Make serializer for some common access There is no right or wrong way on where to put your business logic in Django. But with the introduction of Django rest framework serializer and the various built-in classes it provides like Viewsets, Generics, etc. We could use serializer as the way to hold our business logic or way to perform some tasks that are a bit hard. Plain Serializer will help you a lot in doing so. Here is a plain serializer that will help us upload a file to R2.\nclass FileUploadSerializer(serializers.Serializer): file = serializers.FileField(required=True, write_only=True) key = serializers.CharField(required=True) file_url = serializers.SerializerMethodField(read_only=True)\ndef get\\_file\\_url(self, obj): if not obj: return None if hasattr(obj, \u0026quot;key\u0026quot;): return obj.key if obj.get(\u0026quot;key\u0026quot;): return boto3.get\\_presigned\\_url(obj.get(\u0026quot;key\u0026quot;)) return None def validate\\_key(self, value): if not value: raise serializers.ValidationError(\u0026quot;Key is required\u0026quot;) return value def create(self, validated\\_data): \\# here file is temporary file file = validated\\_data.pop(\u0026quot;file\u0026quot;) key = validated\\_data.get(\u0026quot;key\u0026quot;) boto3.upload\\_temporary\\_file\\_to\\_s3(file, key) return validated\\_data R2 is an alternative to S3 provided by Cloudflare and is too cheap compared to what AWS charges. Downside being that there is no way to replicate data. But it doesn’t incur bandwidth out charge.\nUse SerializerMethodField for custom get logic You can also use SerializerMethodField() to put custom business logic in the viewsets. This is particularly useful when using doing some complex operation on the data. Here is an example where I get pre-signed URL from R2\nclass PostSerializer: mp3_url = serializers.SerializerMethodField(read_only=True) like_id = serializers.SerializerMethodField(read_only=True)\nseconds\\_played = serializers.SerializerMethodField(read\\_only=True) def get\\_seconds\\_played(self, obj): request = self.context.get(\u0026quot;request\u0026quot;) if not request: return 0 if not request.user.is\\_authenticated: return 0 beats\\_played = BeatPlay.objects.filter(user=request.user, beat=obj).first() print(\u0026quot;beats\\_played\u0026quot;, beats\\_played) if not beats\\_played: return 0 return beats\\_played.seconds\\_played def get\\_like\\_id(self, obj): request = self.context.get(\u0026quot;request\u0026quot;) if not request: return None if not request.user.is\\_authenticated: return None like = BeatLike.objects.filter(user=request.user, beat=obj).first() if like: return like.pk return None def get\\_mp3\\_url(self, obj): return boto3.get\\_presigned\\_url(obj.mp3) Serializer Context: Serializer context is an extra dict argument passed with the serializers so that it can be used later on from within the serializer. It is generally used to pass the request to the serializer and later in the data validation or any of the serializer methods.\nfrom rest_framework import serializers from examples.models import Resource\nresource = Resource.objects.get(id=1) serializer = ResourceSerializer(resource, context={\u0026lsquo;key\u0026rsquo;: \u0026lsquo;value\u0026rsquo;})\nThen you can fetch it inside the serializer class from the self.context dictionary like so:\nfrom rest_framework import serializers from examples.models import Resource\nclass ResourceSerializer(serializers.ModelSerializer): class Meta: model = Resource fields = \u0026lsquo;__all__\u0026rsquo; def to_representation(self, instance): representation = super().to_representation(instance) representation[\u0026lsquo;key\u0026rsquo;] = self.context[\u0026lsquo;key\u0026rsquo;] return representation\nOur serializer output will now contain key with value. This is also useful when you want to get in user specific data. Say get_user_has_liked_the_post method. This output of this method is relative to each user, and for the serializer field method we can use self.context and user to get the like_id of the user.\nclass BeatSerializer(serializers.ModelSerializer): like_id = serializers.SerializerMethodField(read_only=True)\ndef get\\_like\\_id(self, obj): request = self.context.get(\u0026quot;request\u0026quot;) if not request: return None if not request.user.is\\_authenticated: return None like = BeatLike.objects.filter(user=request.user, beat=obj).first() if like: return like.pk return None To pass in the context to serializer we use `context=` parameter.\nDynamically modifying fields Once a serializer has been initialized, the dictionary of fields that are set on the serializer may be accessed using the .fields attribute. Accessing and modifying this attribute allows you to dynamically modify the serializer.\nModifying the fields argument directly allows you to do interesting things, such as changing the arguments on serializer fields at runtime, rather than at the point of declaring the serializer.\nclass DynamicFieldsModelSerializer(serializers.ModelSerializer): \u0026quot;\u0026quot;\u0026quot; A ModelSerializer that takes an additional `fields` argument that controls which fields should be displayed. \u0026quot;\u0026quot;\u0026quot;\ndef \\_\\_init\\_\\_(self, \\*args, \\*\\*kwargs): \\# Don't pass the 'fields' arg up to the superclass fields = kwargs.pop('fields', None) \\# Instantiate the superclass normally super().\\_\\_init\\_\\_(\\*args, \\*\\*kwargs) if fields is not None: \\# Drop any fields that are not specified in the \\`fields\\` argument. allowed = set(fields) existing = set(self.fields) for field\\_name in existing - allowed: self.fields.pop(field\\_name) This is how we can change update Django serializers to load dynamic fields.\nBut these are not the only tricks that you can achieve in serializers. There are many other tricks. Why not do one thing ? You comment your tricks so that the medium Django devs can learn from it. 😌\nOh Hello, thanks for staying till the end. Do you know I am available on LinkedIn too? Let\u0026rsquo;s connect there, dear. Click me pita shree 🤌\nAlso, I have a template for quick Django projects. Comes preinstalled with Django, DRF, celery, CORS headers, etc. Why not give a look\nGitHub - n1rjal/djate: My Django template to use _My Django template to use. Contribute to n1rjal/djate development by creating an account on GitHub._github.com Stackademic 🎓 Thank you for reading until the end. Before you go:\nPlease consider clapping and following the writer! 👏 Follow us X | LinkedIn | YouTube | Discord Visit our other platforms: In Plain English | CoFeed | Venture | Cubed Tired of blogging platforms that force you to deal with algorithmic content? Try Differ More content at Stackademic.com ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/take-your-django-serializer-game-to-the-next-level-aa8ad367d25d/","tags":null,"title":"Take Your Django Serializer Game to the Next Level"},{"categories":[],"content":"In Neovim, the scope that regular expression select group is out of this world. Here is a screencast of me making a json object out of just text data. 🧑‍💻\nNeovim has been one of those tool, that I had been procastinating on for majority of my carrer. Now, I have come to embrace it and I am a month old neovim users. You can read more about this here.\nMy journey to VIM, from 😕 to 😄\n_Vim has been throne till my software development. Something that I always ignored and looked away from. Here I would…_blog.stackademic.com Here our text input follows a pattern. Pattern like of a csv file. Fields are separated by comma ,\nWe will have to select that and use the find and replace command. The keybinding for that is\n:\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;s/\nYou will only need to press :s as :’\u0026lt;,’\u0026gt; comes due to selection done in the visual line mode\nThe syntax for the find and replace command is\ns/\u0026lt;input_regex\u0026gt;/replacement string/gc\nHere,\ng,c are flags like global means all and c means confirmation.\nIt will ask for prompt\nSelect groups are those characters that are based upon the values provided in the input selection regular expression.\nHere using \\v means that we willn’t have to escape brackets. In the above example. the target groups are\n(*.), (*.), (*.) -\u0026gt; Everything from beginning till 1st comma, Between 1st and 2nd comma and everything else. We can reference those selection group on the replace part using \\1 \\2 and \\3 in the right side. \\0 means everything. It is like the syntax in the awk command. I also used some json like fields to add extra text in the replace side.\nIf you guessed the replace part, you can see that the output of this must look like some JSON structure. You are right.🥳 So final output looks like this.\nTricks like this has made something more effective in me and I love tricks. You might have some tricks that I may not know. Share me your NeoVim tricks.\nI want to find a way to reference registers in the replace part of find and replace. Imagine if we could use register content in replace part. This is what I will be looking into.\n#neovim #vim #programming Stackademic Thank you for reading until the end. Before you go:\nPlease consider clapping and following the writer! 👏 Follow us on Twitter(X) , LinkedIn , and YouTube . Visit Stackademic.com to find out more about how we are democratizing free programming education around the world. ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/vim-selection-groups-6bd0ed330298/","tags":null,"title":"Vim Selection Groups"},{"categories":[],"content":"I have been diving into the working of rust and I am loving how rust is just opposite of my primary language like typescript/javascript enums and structs just works like C++ or C. I am loving rust and will probably add more content on comparing rust with typescript.\nThe CLI tool is linked to the github repository below. Do give a visit and decide if it is worthy of a star or not.\nGitHub - n1rjal/rss_rust_parser: A rss parser built on rust\n_A rss parser built on rust. Contribute to n1rjal/rss_rust_parser development by creating an account on GitHub._github.com Note that this is my 1st project in rust which can be useful in my daily life and I think there is huge space of improvement and I am open to feedback.\nThe tool mentioned here can be a great tool or some sort of timewaste depending upon how you feel. I build it whilst I was learning rust.\nIt does 3 tasks:\nSource Adding\nIt simply means that we are adding a source for a blog provider. A blog provider can be many things like a medium publication, medium user or any blog providers that support rss feed and obeys the structure declared in the source code.\nTo get source of your favorite blogger, technical writer please use any of these rules\nSyncing\nSyncing is simply the process of adding the latest blogs from all of the source. The command is simple. It loops through all the source and parses the latest blogs from every single one of the sources.\nSearching\nSearching is a process where you search for blogs based on the title based on LIKE query in sqlite and has and features like page number and limit.\nIn a modern terminal like warp, I can click the url here and read the blog over there.\nTechnology Used\nRust: Programing language Serde: For seralizing and deserialzing Clap: For building command line args Tokio: For async await support serde_xml_rs: For parsing rss xml document Want to use it ?\nClone the github repository Install rust in your system project dependencies using cargo install Build the executable using cargo build command Add the executable in your $PATH Future Plans:\nSupport for more rss xml schemas Make it able to parse youtube channels, itunes, hackernoon general rss feed xml too. Add axum based rest api support Schedule syncing process every 5 hours Add support with local notifications in Mac, Windows and Linux Enable siri to work with it. I like to write about technology and programming on LinkedIn. So, let’s get connected there. Here are my socials where you can follow me.\nhttps://www.linkedin.com/in/nirjalpaudel/ https://github.com/n1rjal/ Stackademic Thank you for reading until the end. Before you go:\nPlease consider clapping and following the writer! 👏 Follow us on Twitter(X) , LinkedIn , and YouTube . Visit Stackademic.com to find out more about how we are democratizing free programming education around the world. ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/with-this-rust-tool-i-dont-see-feeds-now-e3f2d013ea80/","tags":null,"title":"With this rust tool, I don’t see feeds now"},{"categories":[],"content":"NestJS is a huge framework built on top of TypeScript, JavaScript also uses Express or Fasitfy as an underlying mechanism to route requests. It uses decorator-based syntax and the concept in NestJS is similar to that of Angular. The source code looks similar to that of Spring boot, Dotnet MVC. Similar in the sense that they all follow dependency injection and IOC principles.\nNestjs is heavily inspired by Angular\nI am trying to conclude the documentation of NestJS which can be found here. https://docs.nestjs.com/ in this writing.\nI have been working on a code base built on nestjs for the last 3 years and I have seen how things changed over time in nestjs. Now, lets leave me out of the discussion and lets disscuss on tiny cute classes in nestjs and its functionalities. Shall we ?\nController Controller as name suggest is a class that are used to define our routes to the class. It’s is decorated with Controller class and the decorator expects a url path string that will trigger its excution. Every methods in controllers are decorated with method specific decorators like Get, Post, Patch, Put, Delete and it assumes you provide it with a path.\n@Controller(\u0026rsquo;/user\u0026rsquo;)\nexport class UserController {\nconstructor(private readonly userService: UserService) {}\n// to signup user\n// GET: /user/signUp\n@Post(\u0026lsquo;signup\u0026rsquo;)\n@Public()\nasync signUpUser(@Body() signUpUserDto: SignUpUserDto) {\nreturn this.userService.signUpUser(signUpUserDto);\n}\n// to get user profile\n// GET: /user/profile\n@Get(\u0026lsquo;profile\u0026rsquo;)\nasync getUserProfile(@LoggedInUser() user: User) {\nreturn user;\n}\n}\nEach of the methods can also be decorated with decorators like @Body, @Query, or @Param that puts request body, query params or url path params into it. Each one of it expects a string to be provided to it which will map the string to the value there. See how userService is provided in controller and how it is being called even without an instance of it being provided.\n2. Service\nService is where our business logic resides. Generally, services are injected with other services or repository layers. Here is an example of service in Nestjs. Now here you can see that it has some other services and repositories in its parameter.\nYou saw the same in controllers as well, the object will be in place all thanks to Dependency injection and IOC container.\n@Injectable()\nexport class UserService {\nconstructor( @InjectRepository(User)\nprivate readonly userRepository: BaseRepository,\nprivate readonly em: EntityManager,\nprivate readonly authService: AuthService, ) {}\n/**\n* This function creates a new user with email, password, and metadata, persists it to the database,\n* and returns a sign-in response for the newly created user.\n* @param {SignInUserDto} signUpUser - The parameter `signUpUser` is of type `SignInUserDto`, which\n* is likely a data transfer object containing information about a user signing up for an account,\n* such as their email and password.\n* @returns The function `signUpUser` returns a Promise that resolves to a `SignInResponse` object.\n*/\nasync signUpUser(signUpUser: SignInUserDto): Promise\u0026lt;SignInResponse\u0026gt; {\nconst newUser = this.userRepository.create({\nemail: signUpUser.email,\npassword: signUpUser.password,\nmetaData: this.INITIAL_BUDGET_METADATA,\n});\nawait this.em.persistAndFlush(newUser);\nreturn await this.signInUser({\nemail: signUpUser.email,\npassword: signUpUser.password,\n});\n}\n/**\n* This function retrieves a user\u0026rsquo;s profile by their ID and throws an exception if the user is not\n* found.\n* @param {string} userId - The `userId` parameter is a string that represents the unique identifier of\n* a user. It is used to search for a user\u0026rsquo;s profile in the database.\n* @returns The function `getUserProfile` returns a Promise that resolves to a `User` object.\n*/\nasync getUserProfile(userId: string): Promise\u0026lt;User\u0026gt; {\nconst userProfile = await this.userRepository.findOne({\nid: userId,\n});\nif (!userProfile) throw new NotFoundException(\u0026lsquo;User not found\u0026rsquo;);\nreturn userProfile;\n}\n}\nLeanr more aboutDependency injection\n_Nest is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript…_docs.nestjs.com These are the building block of nestjs but there are many other types of classes in nestjs, some of them are disscussed below in brief\nBefore we move into other classes, please remember this peice of information from nestjs\n3. Guards\nUse for authorizing user implements CanActivate Interface logic in canActivate method returns boolean | Promise\u0026lt;boolean\u0026gt; | Observable\u0026lt;boolean\u0026gt; proceeds to next part of lifecycle on truthy result apply globally or use @UseGuards() method // example of guard thats accepts only medium authorization\n@Injectable()\nexport class MediumGuard implements CanActivate {\nconstructor() {}\nasync canActivate(context: ExecutionContext): Promise\u0026lt;boolean\u0026gt; {\nconst request = context.switchToHttp().getRequest();\nconst token = this.extractTokenFromHeader(request);\nif (!token) {\nthrow new UnauthorizedException();\n}\ntry {\nif (token!==\u0026ldquo;medium\u0026rdquo;)\nthrow UnAuthorizedException(\u0026ldquo;Use medium 😉\u0026rdquo;)\n} catch {\nthrow new UnauthorizedException();\n}\nreturn true;\n}\n4. Interceptors\nuse for modifying request or response implements NestInterceptor logic in intercept method must know RxJS apply it globally or use @UseInterceptors() method import { Injectable, NestInterceptor, ExecutionContext, CallHandler } from \u0026lsquo;@nestjs/common\u0026rsquo;;\nimport { Observable } from \u0026lsquo;rxjs\u0026rsquo;;\nimport { tap } from \u0026lsquo;rxjs/operators\u0026rsquo;;\n// a simple logging interceptor\n@Injectable()\nexport class LoggingInterceptor implements NestInterceptor {\nintercept(context: ExecutionContext, next: CallHandler): Observable\u0026lt;any\u0026gt; {\nconsole.log(\u0026lsquo;Before\u0026hellip;\u0026rsquo;);\nconst now = Date.now(); return next .handle() .pipe( tap(() =\u0026gt; console.log(\\`After... ${Date.now() - now}ms\\`)), ); }\n}\n5. Pipes\nUse for validation/transformation of controller params Use builtin pipes for validation by providing Provide as second parameter to @Param(), @Body() or @Query() or use globally, For custom Pipe, create a class which implements PipeTransform custom logic in transform method import { ArgumentMetadata, Injectable, PipeTransform } from \u0026ldquo;@nestjs/common\u0026rdquo;;\n// a simple comma seperated string value to array transform pipe\n@Injectable()\nexport class ParseCommaSeparatedPipe\u0026lt;I extends string, J\u0026gt;\nimplements PipeTransform\n{\ncommaRegex = /[,]/;\ntransform(value: I, metadata: ArgumentMetadata): J[] {\nif (value.length === 0) return [];\nreturn value.split(\u0026quot;,\u0026quot;).map((item) =\u0026gt; item as J); }\n}\n6. Filters\ncan be though of as a catch block like in cpp or python can be generic catch or specific catch code in catch() method Decorated by Catch decorator which takes HttpException import { ExceptionFilter, Catch, ArgumentsHost, HttpException } from \u0026lsquo;@nestjs/common\u0026rsquo;;\nimport { Request, Response } from \u0026rsquo;express\u0026rsquo;;\n@Catch(HttpException)\nexport class HttpExceptionFilter implements ExceptionFilter {\ncatch(exception: HttpException, host: ArgumentsHost) {\nconst ctx = host.switchToHttp();\nconst response = ctx.getResponse\u0026lt;Response\u0026gt;();\nconst request = ctx.getRequest\u0026lt;Request\u0026gt;();\nconst status = exception.getStatus();\nresponse .status(status) .json({ statusCode: status, timestamp: new Date().toISOString(), path: request.url, }); }\n}\nThere are many other types of classes in nestjs. which you can find in the official docs. I do nestjs most of the time and make sure you respond with what I left here. I may do part 2 and may write many things on nestjs. if you love it.\nDocumentation | NestJS - A progressive Node.js framework\n_Nest is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript…_docs.nestjs.com I like to write about technology and programming on LinkedIn. So, let’s get connected there. Here are my socials where you can follow me.\nhttps://www.linkedin.com/in/nirjalpaudel/ https://github.com/n1rjal/ In Plain English Thank you for being a part of our community! Before you go:\nBe sure to clap and follow the writer! 👏 You can find even more content at PlainEnglish.io 🚀 Sign up for our free weekly newsletter . 🗞️ Follow us on Twitter (X), LinkedIn , YouTube , and Discord . ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/every-little-cute-classes-in-nestjs-and-its-functionalities-96b76cd259df/","tags":null,"title":"Every Class in NestJS and Its Functionalities"},{"categories":[],"content":"Tell me how many did you know by responding to the article and you may share this with your network to find out how many they know. These are some of the most underrated features in typescript. So, let\u0026rsquo;s begin shall we?\nUsing FlatMap Flat Map in javascript is a great technique which you can learn here . Flat map essentially conbines techniques of map and filter Array method into one. I will suggest you to use flatMap() over combination of filter() and map().\nFlatMap takes single pass and doesn’t produce intermediate array but filter ()and map() combination produces an intermediate array.\n// using filterAndMap\nconsole.time(\u0026ldquo;filterAndMap\u0026rdquo;)\nconst numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\nconst squaredOddNumbers = numbers\n.filter(num =\u0026gt; num % 2 !== 0)\n.map(num =\u0026gt; num * num)\nconsole.log(squaredOddNumbers); // [1, 9, 25, 49, 81]\nconsole.timeEnd(\u0026ldquo;filterAndMap\u0026rdquo;)\nconsole.time(\u0026ldquo;filterAndMap\u0026rdquo;)\nconst numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\nconst squaredOddNumbers = numbers.flatMap(num =\u0026gt;\nnum % 2 !== 0 ? [num * num] : []\n);\nconsole.log(squaredOddNumbers); // [1, 9, 25, 49, 81]\nconsole.timeEnd(\u0026ldquo;filterAndMap\u0026rdquo;)\n2. Order of Array methods\nArray method are some of the most important methods that helps us to interact with an array. There are many array methods in javascript. Most popular array methods are .filter(), .find(), .map(), .reduce(). They can be merged together to produce some wonderful patterns like these\n// a array methods that sorts only the array\n// for only odd numbers and raises it by power of 3\nnumbers\n.sort((a, b) =\u0026gt; a - b)\n.filter((n) =\u0026gt; n % 2 !== 0)\n.map((n) =\u0026gt; n ** 3);\nIn a glance, the program above looks nice right but here is a big problem. Notice how we sorted for numbers 1st and then we moved on to filter right. We could have done less task if we used filter 1st and then sort and raise the power. This way, we can optimize a group of array methods chanined by (.)\nThe optimal code for above is\nconst numbers = [9, 3, 6, 4, 8, 1, 2, 5, 7];\n// a array methods that sorts only the array\n// for only odd numbers and raises it by power of 3\nnumbers\n.filter((n) =\u0026gt; n % 2 !== 0)\n.sort((a, b) =\u0026gt; a - b)\n.map((n) =\u0026gt; n ** 3);\n3. Not using reduce enough.\nI have seen this problem with a lot of frontend developers. While a package like react-charts asks data in object like structure and but the implementation of react-charts asks data in a format grouped by a key so I have seen most developers using .forEach() method or incorectly using map() method like these\nfetch(\u0026ldquo;https://jsonplaceholder.typicode.com/todos/\" )\n.then(res=\u0026gt;res.json())\n.then(todos=\u0026gt;{\n// using Map const todosForUserMap = {}; todos.forEach(todo\\=\u0026gt;{ if (todosForUserMap\\[todo.userId\\]){ todosForUserMap\\[todo.userId\\].push(todo); }else{ todosForUserMap\\[todo.userId\\] = \\[todo\\]; } }) console.log(todosForUserMap) })\nThis method here is good as it uses forEach method and not map method. Map method is clearly not to be used here as an array will be build for each of the elements behind the scene. Lets say if array if of 1000 entries then a 1000 entries null array will be created in map, this creation of array will not happen in forEach()\nInstead of using any of the methods shown above, a rather clean and readable approach would have been to use Array reduce method the above code is now corrected as\nfetch(\u0026ldquo;https://jsonplaceholder.typicode.com/todos/\" )\n.then(res=\u0026gt;res.json())\n.then(todos=\u0026gt;{\n// using Map const todosForUserMap = todos.reduce((accumulator, todo)=\u0026gt;{ if (accumulator\\[todo.userId\\]) accumulator\\[todo.userId\\].push(todo); if (!accumulator\\[todo.userId\\]) accumulator\\[todo.userId\\] = \\[todo\\]; return accumulator; },{}) console.log(todosForUserMap) })\nThis doesn’t create any unnecessary arrays and is much cleaner and is better to use. It is as similar to forEach() but I will suggest this as it is more cleaner and easier to understand.\n4. Not using Generators enough\nGenerators and Iterators are probably among those peice of code a javascript developers doesn’t use and its knowledge is only limited to coding interview. In data fetching scenario, the data can be unlimited in the database/API in huge volume and you will have to stream it in the frontend. In this case, the most used solution in react is the infinite loading solution.\nHow would you implement infinite loading like feature in nodejs server or vanilla javascript ?\nThis is where iterators are really useful. Instead of streaming the flood of data in request in local storage or some places where you can retrieve for later uses. This is one of the methods of doing so using async generators. By this way we can solve infinite loading like problem in JS.\nasync function *fetchProducts(){\nwhile (true){\nconst productUrl = \u0026ldquo;https://fakestoreapi.com/products?limit=2\"; const res = await fetch(productUrl)\nconst data = await res.json()\nyield data;\n// manipulate the UI here like\n// or save it in DB or somewhere else\n// use it as a side effect place\n// even if some condition matches, break the flow\n}\n}\nasync function main() {\nconst itr = fetchProducts();\n// this should be called based on user interaction\n// or other tricks as you don\u0026rsquo;t want inifinite loading.\nconsole.log( await itr.next() );\n}\nreturn main()\n5. Not using native Javascript classes enough\nJavascript comes pack with native javascript classes that can help you create/instantiate things like URL, Headers, etc pretty easily. We might have seen someone trying to query params in URL like this.\nasync function getUrl(userId, limit, category){\nreturn `https://fakestoreapi.com/products${category ? `/category/${category}` : \u0026ldquo;\u0026rdquo;}${limit ? Number(limit):\u0026rdquo;\u0026rdquo;}${userId? Number(userId):\u0026rdquo;\u0026quot;}`; }\nThe code above is messy and is likely to break and will require you to add some rule in the end each time, some other parameter is to be added, by using the native class like URL we can improve our code. Improved code looks like this.\nfunction constructURL(category, limit, userId) {\nconst baseURL = \u0026ldquo;https://fakestoreapi.com/products\"; const url = new URL(baseURL);\nconst params = new URLSearchParams();\nif (category) url.pathname += `/category/${category}`;\nif (limit) params.append(\u0026rsquo;limit\u0026rsquo;, Number(limit).toString());\nif (userId) params.append(\u0026lsquo;userId\u0026rsquo;, Number(userId).toString());\nurl.search = params.toString();\nreturn url.toString();\n}\nThis way, you can handle complex URL-building conditions within the same file. Did you know that the the URL object over here follows BuilderPattern, it is one of the many design patterns you can implement in your code to hide complex logic away in a separate place and it improves readability.\nI like to write about technology and programming on LinkedIn. So, let\u0026rsquo;s get connected there. Here are my socials where you can follow me.\nhttps://www.linkedin.com/in/nirjalpaudel/ https://github.com/n1rjal/ In Plain English Thank you for being a part of our community! Before you go:\nBe sure to clap and follow the writer! 👏 You can find even more content at PlainEnglish.io 🚀 Sign up for our free weekly newsletter . 🗞️ Follow us on Twitter (X), LinkedIn , YouTube , and Discord . ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/i-bet-you-dont-use-these-javascript-tricks-and-pratices-5ab5438ed4c8/","tags":null,"title":"I Bet You Don’t Use These JavaScript Tricks and Practices"},{"categories":[],"content":"Whenever I was looking into the TypeScript Date class constructor implementation, I always wondered how its constructor signature worked like that, how it can have many signature, how can it work with 1st argument as number or string or an instance of itself. Every time I tried to implement the constructor signature in TypeScript using the documentation like TypeScript says I was getting type error shown below.\nI was working on node-nepali-datetime open source package in github.You might be thinking now that this is reinventing the wheel. The reason is that Nepal is around 60 years into the future. The first month of Nepalse calender, the Bikram Sambat calender, is Baisakh. It falls somewhere around April and has other similar features like the English (A.D) calender.\nBut whenever I looked into typescript implementation for date. I could see something that there were 5 different overload for date.\nIn the fifth constructor implementation, I obeserved that the typescript doc string can be the reason behind this implementation then I tried putting doc string in places.\n/\\*\\* \\* Creates NepaliDate instance from current date \\* @example new Date() \\*/ constructor() /\\*\\* \\* Create NepaliDate instance from provided english date \\* \\* @param {Date} date \\* \\* @example \\* const nepaliDate = new NepaliDate( new Date('2020-01-01') ) \\* \\*/ constructor(date: Date) /\\*\\* \\* Create NepaliDate instance from using a provided english date \\* @param {NepaliDate} date: nepali date value provided as a value. \\* @example \\* const nepaliDateOld = new NepaliDate('2080-01-01') \\* const nepaliDate = new NepaliDate( nepaliDateOld ) \\* \\*/ constructor(date: NepaliDate) /\\*\\* \\* Create NepaliDate instance by parsing a provided string value \\* @param {string} value: string date time. \\* @example \\* const nepaliDate = new NepaliDate('2080-01-01') \\* \\*/ constructor(value: string) /\\*\\* \\* Create NepaliDate instance by parsing a provided numeric value \\* @param {number} value: numeric value \\* @example \\* const n = new NepaliDate(new Date(373314600000)) \\* \\*/ constructor(value: number) /\\*\\* \\* Create NepaliDate instance by parsing a provided time string with format provided \\* @param dateString: string date time \\* @param format: string format of the date provided \\* @example \\* const n1 = new NepaliDate('2042/08/12 14-05-23.789', 'YYYY/MM/DD HH-mm-ss.SSS') \\* \\*/ constructor(dateString: string, format: string) /\\*\\* \\* Creates a new instance of the Date class. \\* \\* @constructor \\* @param {number} year - The year. \\* @param {number} month - The month (0-11, where 0 is January and 11 is December). \\* @param {number=} day - The day of the month (1-31). \\* @param {number=} hour - The hour of the day (0-23). \\* @param {number=} minute - The minute (0-59). \\* @param {number=} second - The second (0-59). \\* @param {number=} ms - The milliseconds (0-999). \\* \\* @example \\* const \\[year, month, day\\] = \\[2080, 1, 12\\] \\* const hour = 12 \\* const minute = 30 \\* const second = 45 \\* const ms = 500 \\* const nd = new NepaliDate(year, month, day, hour, minute, second, ms) \\*/ constructor( year: number, month: number, day?: number, hour?: number, minute?: number, second?: number, ms?: number ) {} Unforunately, the same type trouble still persisted, I tried looking into various ways of generalizing many overloads into a final constructor. Before my PR, the project had the following implementation\nconstructor(\u0026hellip;args: any[]) {\nif (args.length === 0) {\nthis._setDateObject(new Date())\n} else if (args.length === 1) {\nconst e = args[0]\nif (typeof e === \u0026lsquo;object\u0026rsquo;) {\nif (e instanceof Date) {\nthis._setDateObject(e)\n} else if (e instanceof NepaliDate) {\nthis.timestamp = e.timestamp\nthis.year = e.year\nthis.yearEn = e.yearEn\nthis.month = e.month\nthis.monthEn = e.monthEn\nthis.day = e.day\nthis.dayEn = e.dayEn\nthis.hour = e.hour\nthis.minute = e.minute\nthis.weekDay = e.weekDay\n} else {\nthrow new Error(\u0026lsquo;Invalid date argument\u0026rsquo;)\n}\n} else if (typeof e === \u0026rsquo;number\u0026rsquo;) {\nthis._setDateObject(new Date(e))\n} else if (typeof e === \u0026lsquo;string\u0026rsquo;) {\n// Try to parse the date\nthis.set.apply(this, parse(e))\n} else {\nthrow new Error(\u0026lsquo;Invalid date argument\u0026rsquo;)\n}\n} else if (\nargs.length === 2 \u0026amp;\u0026amp;\ntypeof args[0] === \u0026lsquo;string\u0026rsquo; \u0026amp;\u0026amp;\ntypeof args[1] === \u0026lsquo;string\u0026rsquo;\n) {\nconst [dateTimeString, format] = args\nthis.set.apply(this, parseFormat(dateTimeString, format))\n} else {\nthis.set(\nargs[0], // year\nargs[1], // month\nargs[2] ?? 1, // day\nargs[3] ?? 0, // hour\nargs[4] ?? 0, // minute\nargs[5] ?? 0, // second\nargs[6] ?? 0 // ms\n)\n}\n}\nThe above implemention is almost perfect but, then friendly neighbour hood eslint yelled about using any. I even considered making an exception to the rule using the following.\n@typescript-eslint/no-explicit-any\nBut this is an open source project and I was not bound by time limit or pressured to delievered fast and no one was depending on me for this. So, I decided to dive more deep into working of typescript and constructor.\nLuckily, javascript has an awesome feature called arguments . I tried to look into it to find out if it could be more helpful. This is how arguments work. I was a bit skeptical that it would throw a type error like other implementation but to my suprise it didn’t raise any type error in the editor.\nfunction func1(a, b, c) {\nconsole.log(arguments)\n// Excepted output: 1, 2, 3\nconsole.log(arguments[0]);\n// Expected output: 1\nconsole.log(arguments[1]);\n// Expected output: 2\nconsole.log(arguments[2]);\n// Expected output: 3\n}\nfunc1(1, 2, 3);\nThe final constructor code looks something like this. No type errors are thrown and the code supports all the types correclty. After adding some typescript doc string. This code was good to go for me. But there is a catch.\nconstructor() constructor(date: Date) constructor(date: NepaliDate) constructor(value: string) constructor(value: number) constructor(dateString: string, format: string) constructor( year: number, month: number, day?: number, hour?: number, minute?: number, second?: number, ms?: number ) constructor() { if (arguments.length === 0) { this.\\_setDateObject(new Date()) } else if (arguments.length === 1) { const e = arguments\\[0\\] if (typeof e === 'object') { if (e instanceof Date) { this.\\_setDateObject(e) } else if (e instanceof NepaliDate) { this.timestamp = e.timestamp this.year = e.year this.yearEn = e.yearEn this.month = e.month this.monthEn = e.monthEn this.day = e.day this.dayEn = e.dayEn this.hour = e.hour this.minute = e.minute this.weekDay = e.weekDay } else { throw new Error('Invalid date argument') } } else if (typeof e === 'number') { this.\\_setDateObject(new Date(e)) } else if (typeof e === 'string') { // Try to parse the date this.set.apply(this, parse(e)) } else { throw new Error('Invalid date argument') } } else if ( arguments.length === 2 \u0026amp;\u0026amp; typeof arguments\\[0\\] === 'string' \u0026amp;\u0026amp; typeof arguments\\[1\\] === 'string' ) { const \\[dateTimeString, format\\] = arguments this.set.apply(this, parseFormat(dateTimeString, format)) } else { this.set( arguments\\[0\\], // year arguments\\[1\\], // month arguments\\[2\\] ?? 1, // day arguments\\[3\\] ?? 0, // hour arguments\\[4\\] ?? 0, // minute arguments\\[5\\] ?? 0, // second arguments\\[6\\] ?? 0 // ms ) } } The catch is that in the actual implemenation of the code where things gets executed, the types information is completely lost resulting in code that checks for every single possible combination of values among the many implemenation using typeof, instanceof and arguments.length combination. The Date code in the javascript is native C++ code, so it was not such helpful for me. But with proper doc string added this code from user prespective is close to the native Date constructor implementation as I can go.\nI took this design descision and I think this really works for now, but if you have any suggestion on why this peice of code sucks or is not good. Let me know. I like to write about technology and programming in linkedin. So, lets get connected there. Here are my socials.\nhttps://www.linkedin.com/in/nirjalpaudel/ n1rjal - Overview\n_Curious about Tech | Nodejs 🩵 | Database 🔥 . n1rjal has 83 repositories available. Follow their code on GitHub._github.com In Plain English Thank you for being a part of our community! Before you go:\nBe sure to clap and follow the writer! 👏 You can find even more content at PlainEnglish.io 🚀 Sign up for our free weekly newsletter . 🗞️ Follow us on Twitter (X), LinkedIn , YouTube , and Discord . ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/overloading-typescript-constructor-like-c-java-or-c-with-a-catch-b23267daec62/","tags":null,"title":"Overloading TypeScript Constructors like C++ or Java with a Catch"},{"categories":[],"content":"Hello everyone 👋👋\nI created a MongoDB database with 10 million documents.😄 My schema is simple and is for a very very basic inventory management system.\nBefore we begin name: string,\nquantity: number,\nHere is a sample of some of the documents.\nThe schema looks simple enough but I have been working with a huge number of documents. To be precise, I am working with 12734005 documents. For those wondering how did I insert these documents here is the python code that helped me did it.\nLink to python Code Let’s talk about count let’s find out which is better in which situation\nBy default, In MongoDB provides us with 3 different count methods.\ncountDocuments() cursor.count() estimatedDocumentCount() 1. countDocuments() it took somewhere between 4 to 10 seconds. Probably caching helped reduce its speed. Let’s discuss this below.\nIf you know aggregation, you can see that countDocuments() is the most accurate but slowest count query among the three. Behind the scene, it does a sequential scan, ** fancy way of saying goes through all documents **, in all documents for the query gets the count. This is the slowest count I found.\ndb.collection.countDocuments() wraps the following aggregation operation and returns just the value of n:\ndb.collection.aggregate([\n{ $match: },\n{ $group: { _id: null, n: { $sum: 1 } } }\n])\nSource: MongoDb Official Documentation 2. cursor.count() MongoDB returns a cursor for collection.find(\u0026lt;query\u0026gt;) type of queries. The cursor has many methods and .count() is one of them. cursor.count() is same as countDocuments() but when its about .find().count() it returns count from collstats. It takes constant time\nThe collStats command returns a variety of storage statistics for a given collection. Source : MongoDb official documentation 3. estimatedDocumentCount() Unlike cursor.count() and countDocuments(), estimatedDocumentCount() does not take any query parameters. It returns the total count of documents. This is an estimated count. But I think it is ok to return the estimated count as no one would actually bother about if the count is right or wrong up to million. Source : MongoDb official documentation Suggestions: Don’t be that guy above Use estimatedDocumentCount() when counting total number of documents. Use find.count() when dealing with the counting of total number of documents with query filters Whenever using query filters, always filter by indexes, as it makes querying faster resulting in faster counts. Try storing count with query filters in a data store like Redis or a new collection and update it periodically. It is better to use pre-computed counts than to hog your database’s CPU. Best way to deal with million documents is by not dealing with millions at one time. Conclusion: I am not the “know all” type of guy. I might be wrong in this blog or you might have some better way to count the documents. Let’s discuss. I like to be proven wrong and I want an opportunity to learn from you guys as well but until then peace out. 😄\n","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/best-way-to-count-documents-in-mongodb-b0c7e7861286/","tags":null,"title":"Best way to count documents in MongoDB"},{"categories":[],"content":"EDIT 1: After many requests from users of this tools, I have decided to remove I prefix from the name of the interface\nYeah, the title is kind of misleading. Who would not write typescript interfaces right? I am not saying to stop writing typescript interfaces, but automate it 🫡\nWhat ? How do we automate creating types ?\nPostman is an API testing tool that can help us test API. It can be used to test API both locally and hosted. It also acts as a documentation for the API you are building and it is programming language independent.\nNow, imagine this, you have full documentation for your API as a postman collection (A Postman collections can be thought of as a folder that contains requests or other collection inside it). Each collection in Postman can be downloaded/saved as a JSON file which has two schema versions. They are collection v2 and collection v2.1 and share the collection as a JSON file.\nNow, lets come back to typescript and interfaces. An interface has a signature for a object that defines all the type of keys inside the object.\n// example of a typescript interface\ninterface Human{\nname: string;\nage: number;\nisMarried: boolean;\n}\nNow imagine this is your collection. This collection here has more than 20 requests. Now lets create type for each requests, query parameters and for every response in the examples.\nA simple typescript type can be created at around 10–15 seconds approximately (without AI tools) and can be created at around 5–7 seconds (with AI tools). Now lets calculate how much time does total interface creation takes? Very long right ? Now how about for 500 requests ? 1000 requests ?\nBut it only takes me 5 seonds to do 500 request. Wow really ? Actually yes. I have a small script that does it for me. It looks at the json file of collection export and generates the typescript types based on the content of the json and creates the typescript interface based on the name of the request or the response name and put the creates a folder with all the interfaces.\nYou can use this command.\nnpx @n1rjal/pm_ts -i -o Here\n-i means the input json file -o means the output directory where the types shall be placed Now, lets try the command and see the results. Here is my work dir in vscode without runing the script.\nNow lets run the script as\nnpx @n1rjal/pm_ts -i export.json -o types\nNow a types folder is created with the following content\nNow lets inspect one of the postman requests\nNow lets see it equivalent type for body. The interface generated has the following content. See how the naming of the request and the url is mapped to the content of the file\n/*\nCalculate Winners\nPOST: {{host}}/competition/:compId/calculate/winners\n*/\nexport interface ICalculateWinners {\nname: string;\ncount: number;\nprizes: string[];\n}\nThis script is now available and registered as a public script in npx and you can give it a star 🌟 if you like what I am doing here.\nGitHub - n1rjal/postman-to-typescript: A simple nodejs script that looks into the postman…\n_A simple nodejs script that looks into the postman collection json and produces typescript interfaces - GitHub …_github.com Stackademic Thank you for reading until the end. Before you go:\nPlease consider clapping and following the writer! 👏 Follow us on Twitter(X) , LinkedIn , and YouTube . Visit Stackademic.com to find out more about how we are democratizing free programming education around the world. ","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/stop-writing-typescript-interfaces-13500311d24c/","tags":null,"title":"Stop Writing TypeScript Interfaces, Automate It"},{"categories":[],"content":"Both Just In Time compiler or JIT and worker processes could be news to you. By the end of this article, you would be able to understand the picture I have provided.\nFor this article, I have created a couple of Postgres tables with huge rows, each of the rows has a relationship with another table. The relationship between them is many-to-one. One of the tables is a product and the other table is a store. Many products have one store referenced by the store_id column. Here is a rough command for SQL `CREATE TABLE` statement\nCREATE TABLE store (\nid SERIAL PRIMARY KEY,\nname VARCHAR(255),\naddress VARCHAR(255),\nphone_number VARCHAR(15)\n);\nCREATE TABLE product (\nid SERIAL PRIMARY KEY,\nname VARCHAR(255),\nprice DECIMAL(10,2),\ndescription TEXT,\nstore_id INT,\nFOREIGN KEY (store_id) REFERENCES store (id)\n);\nI have around 29k stores and around 12 million products. Here is the count of the both\nI haven’t placed any indexing structure for the product table. Now let’s interact with the product table.\nWHERE clause and Count: EXPLAIN ANALYSE SELECT COUNT(*) FROM \u0026ldquo;product\u0026rdquo;\nWHERE \u0026ldquo;price\u0026rdquo; \u0026lt; 10;\nThe result of EXPLAIN ANALYZE shows the following info\nPlanning stage/JIT: The planning stage for the command used the Just In Time compilation. I think every analytical serverless function should use this. Due to JIT compilation, the planning phase time is almost doubled.\nJust In Time Compilation (JIT)\nSuggestions:\nUse JIT for analytical queries. Use JIT for complex sorting queries. Execution stage/Worker process: The execution stage of the query is executed using 2 workers, each of the worker processes scans the table from opposite ends. Each worker is filtering the rows and count results were gathered and a final aggregation was done to get the final count.\nOn worker process:\nThe worker process strategy used spawns 2 process that parallel scans the product and returns the matching rows, here the worker uses the gather node and has done the here partial and the final aggregation used is the COUNT aggregation. Here is a graphic that can help you understand the working principle.\nWhats in the picture I hope you can clearly understand the picture now, but here are the steps involved.\nThe parent process spawns two processes. Two processes work from either end of the table The processing or scanning takes place in our case, it scans via the native CPU code generated due to JIT compilation. The result is partially aggregated meaning total count is generated. The count is handed over to the parent process by the worker process. The 2 worker processes are killed and their result is combined and the output is given to the user. Now you might be wondering what if we increase the total number of workers in the query, let’s do that. Note that this will increase the execution speed of the query but as more processes are used, it will use more memory. Lets me increase the max_parallel_workers and max_parallel_workers_per_gather parameter to and 4 respectively to get more workers to do the task. Learn about them more here.\nHow does the Postgres parallel worker work My PC is 8 core CPU PC and my CS knowledge says that my computer shouldn’t lag till 8 worker processes. Managing process is also time-consuming as launching and killing a process is a time-consuming and expensive time as well. But hey, I am postgres with docker and other background apps are running simultaneously as well. So leaving the theory aside lets make the hands dirty.\nI ran the following query\n-- the value x is the total worker allowed\nSET max_parallel_workers = x;\nSET max_parallel_workers_per_gather = x;\nEXPLAIN ANALYSE SELECT COUNT(*) FROM \u0026ldquo;product\u0026rdquo; WHERE \u0026ldquo;price\u0026rdquo; \u0026lt; 10\nUpon running the query I got the following results\nPostgres query planner is a clever piece of tool and it detected that the execution time was not going to be much better after 5 worker processes and stopped spawning more worker processes when it reached the value of x greater than 5. Even when I was allowed to go more than 5 workers per execution, I didn’t do that and insisted on using 5 worker processes.\nBIG BUT Here’s a big but for y’all. The query I used is pretty simple, right? count the total, so let me spice things up a little bit more with the following query.\nEXPLAIN ANALYSE\nSELECT id FROM \u0026ldquo;product\u0026rdquo; WHERE \u0026ldquo;price\u0026rdquo; \u0026gt; 10\nORDER BY store_id DESC\nLIMIT 1000\nThe query provided below is more “complex” as it has sorting and limiting in it and the query planner looks like this with no worker. Not only that the querying condition has changed as well resulting in more data to look for.\nHere I forced the query planner to not use worker processes.\nPlanning stage: The planning stage remains almost all the same with JIT enforced but here the parameters of the JIT is changed. Options like optimizations, and expressions are set to true. The overall number of functions is changed as well. Planning time is consistent.\nExecution stage: I forced only one worker to be used at this time. To see all the activities it performs, here parallel seq scan is used. Top-N heapsort is used, it shares the time complexity of heapsort but only sorts the top N members( for our case it’s 1000 ) and finally limit happens.\nNow let’s add workers to the picture\nGather Merge node is used as it is expected to be used for queries with sorting enabled.\nHere is the result for various query times.\nAs you can see that using the worker process has significantly decreased the planning time by almost half compared to not being used in both queries. This is a general introduction to worker processes and JIT in Postgresql but do you still with 5 workers used, the query is considered really slow. This is due to the use of seq scan to filter the product table. In the next writing, I would help you on how to improve on that with an introduction to index in Postgres and its type. Until then, you can follow me on my LinkedIn here. My Linkedin Profile .\n","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/postgres-just-in-time-compiler-and-worker-processes-6c7434864078/","tags":null,"title":"Postgres Just In Time Compiler and Worker Processes"},{"categories":[],"content":"Here are some of the few design patterns that you can use to better your MongoDB schema, so you’ll keep your team happy and yourself happier.\nMongoDB is a flexible schema based document database. Flexibility was something that we were craving after many years with SQL. Flexibility is so fun to code and enjoy until your application code is suffering from “What was the schema again?” problem. MongoDB follows document based design principle for modelling things. You can insert as many objects/arrays in MongoDB as long as you don’t hit the limit of 16mb. So, chances of you never discovering the problem until it is very late is high.\nHere are some of the design patterns you can model your schema with\nSchema versioning Pattern: In MongoDB schema, or any NoSQL based DB, schema versioning is a method in which we add a field representing the version of schema that the document obeys. Schema will be read by the application code, and a logic must be in place for handling every possible schema version value.\nSchema version has its own pros and cons.\nPros:\nEasier to handle changes The flexibility of your application grows. Easier to debug and track Cons:\nAdded complexity in the application layer. The database can grow inconsistent over time. Database may be harder to navigate without application logic making it logically coupled with each other. 2. Computed Pattern:\nHave you ever wondered, how can YouTube get the real time total views of a video?\nThe video above has 1.3B views, but if you were to count that in any DB using\ndb.getCollection(\u0026ldquo;video-views\u0026rdquo;).find({}).count();\nThe query above would take ages to count the total views of the video. But on YouTube you can see the total view in an instant right. So let me introduce you to the computed value pattern. Instead of counting the video views every time, you introduce a field in video, say view which will get updated every time when a user views the video and now instead of counting the total views, you can present users with that value.\nThe new documents would be something like this, and your application service should increment the value of views every time someone views the video.\n{\n\u0026ldquo;title\u0026rdquo;: \u0026ldquo;Rick Astley - Never Gonna Give You Up (Official Music Video)\u0026rdquo;,\n\u0026ldquo;description\u0026rdquo;: \u0026ldquo;1987 pop hit, famously used in internet \u0026lsquo;Rickrolling\u0026rsquo; meme\u0026rdquo;,\n\u0026ldquo;videoId\u0026rdquo;: \u0026ldquo;dQw4w9WgXcQ\u0026rdquo;,\n\u0026ldquo;views\u0026rdquo;: 217383786\n}\nPros:\nReal time data is fetched every time This is effective as the computed pattern only does a fraction of work for same result Cons:\nIt may be harder to maintain, if you are computing the values in very short intervals. The data may be incorrect if transactions are not in place 3. Subset Pattern:\nSubset pattern in MongoDB is a pattern in we store a subset of field of a document in a foreign collection. It can be thought of as materialized view for MongoDB. For a big document, say user as\n{\n\u0026ldquo;_id\u0026rdquo;: ObjectId(\u0026ldquo;6155e5b5c3e30c0410c07e84\u0026rdquo;),\n\u0026ldquo;username\u0026rdquo;: \u0026ldquo;johndoe\u0026rdquo;,\n\u0026ldquo;email\u0026rdquo;: \u0026ldquo;john.doe@example.com \u0026rdquo;,\n\u0026ldquo;password\u0026rdquo;: \u0026ldquo;$2a$12$R1..K94OiVJ.gNwINZfNkuNpJcoCJErjy.NxJmp/9cGJbEjK2rJ4S\u0026rdquo;,\n\u0026ldquo;profile\u0026rdquo;: {\n\u0026ldquo;firstName\u0026rdquo;: \u0026ldquo;John\u0026rdquo;,\n\u0026ldquo;lastName\u0026rdquo;: \u0026ldquo;Doe\u0026rdquo;,\n\u0026ldquo;birthdate\u0026rdquo;: ISODate(\u0026ldquo;1980-01-01T00:00:00Z\u0026rdquo;),\n\u0026ldquo;gender\u0026rdquo;: \u0026ldquo;male\u0026rdquo;,\n\u0026ldquo;address\u0026rdquo;: {\n\u0026ldquo;street\u0026rdquo;: \u0026ldquo;123 Main St\u0026rdquo;,\n\u0026ldquo;city\u0026rdquo;: \u0026ldquo;Anytown\u0026rdquo;,\n\u0026ldquo;state\u0026rdquo;: \u0026ldquo;CA\u0026rdquo;,\n\u0026ldquo;zip\u0026rdquo;: \u0026ldquo;12345\u0026rdquo;\n},\n\u0026ldquo;phoneNumbers\u0026rdquo;: {\n\u0026ldquo;home\u0026rdquo;: \u0026ldquo;555-1234\u0026rdquo;,\n\u0026ldquo;work\u0026rdquo;: \u0026ldquo;555-5678\u0026rdquo;,\n\u0026ldquo;mobile\u0026rdquo;: \u0026ldquo;555-9012\u0026rdquo;\n},\n\u0026ldquo;education\u0026rdquo;: [\n{\n\u0026ldquo;degree\u0026rdquo;: \u0026ldquo;Bachelor of Science\u0026rdquo;,\n\u0026ldquo;major\u0026rdquo;: \u0026ldquo;Computer Science\u0026rdquo;,\n\u0026ldquo;university\u0026rdquo;: \u0026ldquo;University of California, Los Angeles\u0026rdquo;,\n\u0026ldquo;graduationYear\u0026rdquo;: 2002\n},\n{\n\u0026ldquo;degree\u0026rdquo;: \u0026ldquo;Master of Business Administration\u0026rdquo;,\n\u0026ldquo;major\u0026rdquo;: \u0026ldquo;Finance\u0026rdquo;,\n\u0026ldquo;university\u0026rdquo;: \u0026ldquo;Stanford University\u0026rdquo;,\n\u0026ldquo;graduationYear\u0026rdquo;: 2006\n}\n],\n\u0026ldquo;workHistory\u0026rdquo;: [\n{\n\u0026ldquo;company\u0026rdquo;: \u0026ldquo;Acme Corporation\u0026rdquo;,\n\u0026ldquo;position\u0026rdquo;: \u0026ldquo;Software Engineer\u0026rdquo;,\n\u0026ldquo;startDate\u0026rdquo;: ISODate(\u0026ldquo;2002-01-01T00:00:00Z\u0026rdquo;),\n\u0026ldquo;endDate\u0026rdquo;: ISODate(\u0026ldquo;2005-12-31T00:00:00Z\u0026rdquo;)\n},\n{\n\u0026ldquo;company\u0026rdquo;: \u0026ldquo;Widgets, Inc.\u0026rdquo;,\n\u0026ldquo;position\u0026rdquo;: \u0026ldquo;Product Manager\u0026rdquo;,\n\u0026ldquo;startDate\u0026rdquo;: ISODate(\u0026ldquo;2006-01-01T00:00:00Z\u0026rdquo;),\n\u0026ldquo;endDate\u0026rdquo;: ISODate(\u0026ldquo;2010-12-31T00:00:00Z\u0026rdquo;)\n},\n{\n\u0026ldquo;company\u0026rdquo;: \u0026ldquo;XYZ Corp.\u0026rdquo;,\n\u0026ldquo;position\u0026rdquo;: \u0026ldquo;Director of Marketing\u0026rdquo;,\n\u0026ldquo;startDate\u0026rdquo;: ISODate(\u0026ldquo;2011-01-01T00:00:00Z\u0026rdquo;),\n\u0026ldquo;endDate\u0026rdquo;: null\n}\n],\n\u0026ldquo;interests\u0026rdquo;: [\n\u0026ldquo;hiking\u0026rdquo;,\n\u0026ldquo;reading\u0026rdquo;,\n\u0026ldquo;traveling\u0026rdquo;,\n\u0026ldquo;playing guitar\u0026rdquo;\n]\n},\n\u0026ldquo;preferences\u0026rdquo;: {\n\u0026ldquo;language\u0026rdquo;: \u0026ldquo;en\u0026rdquo;,\n\u0026ldquo;theme\u0026rdquo;: \u0026ldquo;light\u0026rdquo;,\n\u0026ldquo;timezone\u0026rdquo;: \u0026ldquo;America/Los_Angeles\u0026rdquo;\n},\n\u0026ldquo;notifications\u0026rdquo;: [\n{\n\u0026ldquo;type\u0026rdquo;: \u0026ldquo;email\u0026rdquo;,\n\u0026ldquo;frequency\u0026rdquo;: \u0026ldquo;daily\u0026rdquo;\n},\n{\n\u0026ldquo;type\u0026rdquo;: \u0026ldquo;sms\u0026rdquo;,\n\u0026ldquo;frequency\u0026rdquo;: \u0026ldquo;weekly\u0026rdquo;\n}\n],\n\u0026ldquo;createdAt\u0026rdquo;: ISODate(\u0026ldquo;2021-09-30T10:15:01Z\u0026rdquo;),\n\u0026ldquo;updatedAt\u0026rdquo;: ISODate(\u0026ldquo;2022-10-01T14:30:05Z\u0026rdquo;)\n}\nWe can store a smaller, collection, say username, which holds a subset of fields from the user document which may look like this.\n{\n\u0026ldquo;_id\u0026rdquo;: ObjectId(\u0026ldquo;605edb98fbf3d639d3cf6c8f\u0026rdquo;),\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Jane Doe\u0026rdquo;,\n\u0026ldquo;email\u0026rdquo;: \u0026ldquo;jane.doe@example.com \u0026rdquo;\n}\nNote: We can achieve the same result using projection operation in MongoDB or $project pipeline in MongoDB aggregation. Now instead of using the user collection for reading the value, we can use username collection.\nPros:\nEffective memory management Shorter disk access time Cons:\nIn case of transaction not being used, the collections may become inconsistent Additional trips to the DB in case of create, update or delete operations 4. Bucket Pattern:\nIn computer science, a bucket refers to a logical collection that holds similar items together.\nFor a log based application that has write heavy usage, the application receives high amount of write operations as compared to read operations. This type of access pattern can be found in a log application like user tracking system, gaming system, etc. The question of how would you divide the given written data is answered by the bucket pattern.\nLet’s say that you are tracking temperature of a room using some devices and storing it in a database. Then a bucket based division can divide the written data records as\nWe can run analytics based on the bucket data, we can also add bucket pattern with computed data pattern to accommodate statistical data for our simplicity, the newer version of documents would look as\n{\ndevice_id: \u0026ldquo;device1\u0026rdquo;,\ntype: \u0026ldquo;2A\u0026rdquo;,\ndate: ISODate(\u0026ldquo;2022-04-01T00:00:00Z\u0026rdquo;),\ntemp: [20.5, 21.3, 22.1, 20.8, 21.7],\nmean_temperature: 21.28,\nstd_temperature: 0.72\n},\n{\ndevice_id: \u0026ldquo;device1\u0026rdquo;,\ntype: \u0026ldquo;2A\u0026rdquo;,\ndate: ISODate(\u0026ldquo;2022-04-01T01:00:00Z\u0026rdquo;),\ntemp: [21.1, 20.9, 21.5, 22.3, 20.4],\nmean_temperature: 21.24,\nstd_temperature: 0.69\n}\nPros:\nGood for IOT implementations Improves querying speed with indexes Great for time series data Cons:\nIncreased storage requirements Increased complexity Proper bucket selection must be done to prevent empty buckets There are few more design pattern in MongoDB like the outlier pattern, Polymorphic pattern for your use cases. Each one of them have their pros and cons. Here is a link to learn more about them. Here are some of the use cases of MongoDB design patterns\nYou can follow me on LinkedIn, as I like to rant about technologies over there. https://www.linkedin.com/in/nirjalpaudel/ MongoDB pattern has its pros and cons and at the end of the day, proper usage of patterns is preventing you a call at 2am in the morning saying that DB is down but on the other hand you will miss the over time pay from your company, so choose wisely extra 💰 or 🛌.\nThank you for reading until the end. Please consider following the writer and this publication. Visit Stackademic to find out more about how we are democratizing free programming education around the world.\n","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/mongodb-design-patterns-708100c07bcb/","tags":null,"title":"Eat the frog: MongoDB Design Patterns"},{"categories":[],"content":"Recently in my country, many hashtag challenges are going viral. Challenges like #couplechallenge, #singlechallenge, #dropyourdopephoto, #dropyourpout etc are coming and going around in social media platform. Is it a good thing? Is it a showoff? I can’t tell you that because I don’t know the reason behind that. LOL\nProgressive Challenges I have seen both sides these challenges. Challenges were made jokes, commitments and many more. One day, I came across #30dayschallenge. I thought one couldn’t do anything in 30days but I decided to touch that hashtag and see all the content using to that hashtag. I was amazed to see that so many people were participating in that challenge. #30dayschallenge captured people from all the niches. It was people challenging themselves from running a mile a day to sleeping 8 hrs a day. The general format of the challenge went like this\n#day1 of #30dayschallenge #niche/topic\nNew Year’s Resolution A year passes and I am sitting pissed off, angry with myself that I couldn’t achieve a thing out of a list of things that I promised myself a year ago. Like most of the people. I could never stick to a plan for more than a couple of week. Again, I lied promised that this time I will do it. Ah shit here we go again A year passes and the same cycle continues. The same problem lies in all of us. If you could stick to a commitment for all over a year, this article is definitely not for you.\nOnly 8% complete their new year’s resolution\nWhy #30dayschallenge Some of my relatives some how managed to sacrifice meat products for a month even being meat hungry in nature. That is too good of a motivation. Islams fast for around a month. If they can do that, I am sure you can do that too. Every single Islamic people is a motivation for all of us.\nMost of us, the average people, take around 21 days to build a habit.\nI am a coder and I have been coding for around 4 years. But learning new language was always a problem for me. I managed to solve this problem by committing to a 30 days challenge. Its #day-19 today and I feel comfortable with the new language. I am learning Node. I feel comfortable with node in day-17 of the challenge. I tried to learn node 3 times before but I never went that far. This has been the personal impact of #30dayschallenge in my life.\nWhat should I challenge myself on? You can challenge yourself on many things. Find a topic that you are lacking behind on. You can focus on your body, relationship or sleep cycle. You can challenge yourself to run a mile each day. You don’t need to be perfect in between or at the end of the challenge. You just need to do it.\nBetter to approach a problem like many pieces to be solved everyday rather than procrastinating everyday\nConclusion It is better to do something rather than doing nothing. The challenge is to bring you out of your comfort zone. Take it as a opportunity to do more. Feel proud afterwards and post it in social media. Lets hope next time, I will find you when I browse through #30dayschallenge in my social medias.\n","permalink":"http://localhost:1313/posts/@nirjalpaudel54312/the-new-challenge-format-20253ebc536e/","tags":null,"title":"The new challenge format"},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.es/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.fr/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.hi/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.jp/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.pl/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.ru/","tags":null,"title":""},{"categories":null,"content":"","permalink":"http://localhost:1313/search/_index.zh-cn/","tags":null,"title":""}]